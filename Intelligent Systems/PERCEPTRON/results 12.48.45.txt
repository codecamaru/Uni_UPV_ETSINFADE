
OCR dataset

values of a from 0.1 to 10,000

#     a        b   E   k  Ete  Ete(%)     Ite [] 

#------- -------- --- --- --- ------- ----------

     0.1      0.1   0  11  14   4.7   [2.3,7.1] 
     1.0      0.1   0  12  17   5.7   [3.1,8.3] 
    10.0      0.1   0  10  15   5.0   [2.5,7.5] 
   100.0      0.1   0  10  15   5.0   [2.5,7.5] 
  1000.0      0.1   0  10  15   5.0   [2.5,7.5] 
 10000.0      0.1   0  10  15   5.0   [2.5,7.5] 



 values of b from 0.1 to 100,000

#     a        b   E   k  Ete  Ete(%)     Ite [] 

#------- -------- --- --- --- ------- ----------

     0.1      0.1   0  11  14   4.7   [2.3,7.1] 
     0.1      1.0   0  12  18   6.0   [3.3,8.7] 
     0.1     10.0   0  17  14   4.7   [2.3,7.1] 
     0.1    100.0   0 123  14   4.7   [2.3,7.1] 
     0.1   1000.0 162 200  11   3.7   [1.5,5.8] 
     0.1  10000.0 538 200  29   9.7   [6.3,13.0] 
     0.1 100000.0 700 200 141  47.0   [41.4,52.6] 



EXPRESSIONS dataset

values of a from 0.1 to 10,000

#     a        b   E   k  Ete  Ete(%)     Ite [] 

#------- -------- --- --- --- ------- ----------

     0.1      0.1   0  50   4   6.0   [0.3,11.6] 
     1.0      0.1   0  50   4   6.0   [0.3,11.6] 
    10.0      0.1   0  50   4   6.0   [0.3,11.6] 
   100.0      0.1   0  50   4   6.0   [0.3,11.6] 
  1000.0      0.1   0  50   4   6.0   [0.3,11.6] 
 10000.0      0.1   0  50   4   6.0   [0.3,11.6] 



 values of b from 0.1 to 100,000

#     a        b   E   k  Ete  Ete(%)     Ite [] 

#------- -------- --- --- --- ------- ----------

     0.1      0.1   0  50   4   6.0   [0.3,11.6] 
     0.1      1.0   0  50   4   6.0   [0.3,11.6] 
     0.1     10.0   0  50   4   6.0   [0.3,11.6] 
     0.1    100.0   0  50   4   6.0   [0.3,11.6] 
     0.1   1000.0   0  63   6   9.0   [2.1,15.8] 
     0.1  10000.0   0  45   4   6.0   [0.3,11.6] 
     0.1 100000.0   0  66   7  10.4   [3.1,17.8] 

VIDEOS dataset

values of a from 0.1 to 10,000

#     a        b   E   k  Ete  Ete(%)     Ite [] 

#------- -------- --- --- --- ------- ----------

     0.1      0.1 1644 200 833  34.8   [32.9,36.7] 
     1.0      0.1 1150 200 732  30.6   [28.7,32.4] 
    10.0      0.1 1052 200 813  33.9   [32.0,35.8] 
   100.0      0.1 1032 200 828  34.6   [32.7,36.5] 
  1000.0      0.1 1026 200 831  34.7   [32.8,36.6] 
 10000.0      0.1 1020 200 826  34.5   [32.6,36.4] 



 values of b from 0.1 to 100,000

#     a        b   E   k  Ete  Ete(%)     Ite [] 

#------- -------- --- --- --- ------- ----------

     0.1      0.1 1644 200 833  34.8   [32.9,36.7] 
     0.1      1.0 2788 200 647  27.0   [25.2,28.8] 
     0.1     10.0 4424 200 673  28.1   [26.3,29.9] 
     0.1    100.0 5565 200 1140  47.6   [45.6,49.6] 
     0.1   1000.0 5566 200 1171  48.9   [46.9,50.9] 
     0.1  10000.0 5590 200 1171  48.9   [46.9,50.9] 
     0.1 100000.0 5590 200 1171  48.9   [46.9,50.9] 


El perceptrón es más sensible a las variaciones del margen (b) que a las variaciones del factor de aprendizaje

Observamos que para los datasets gauss2D y videos no hay convergencia, ya que en el entrenamiento se cometen muchos errores y la E nunca es 0. Estos dos datasets son los que mayor numero de muestras contienen. No son linearmente separables.
Lo que podría indicar que aumentando el número de iteraciones, la k del perceptrón, los resultado podrían mejorar. (pero ha sido computacionalmente más costoso)

camaru@alumno.upv.es@ldsic-vdi07:~/W/SIN/PERCEPTRON$ python experimentk.py videos '.1 1 10 100 1000 10000' '0.1' '300'
#     a        b   E   k  Ete  Ete(%)     Ite [] 

#------- -------- --- --- --- ------- ----------

     0.1      0.1 1506 300 790  33.0   [31.1,34.9] 
     1.0      0.1 1054 300 670  28.0   [26.2,29.8] 
    10.0      0.1 938 300 751  31.4   [29.5,33.2] 
   100.0      0.1 940 300 758  31.6   [29.8,33.5] 
  1000.0      0.1 928 300 759  31.7   [29.8,33.6] 
 10000.0      0.1 942 300 755  31.5   [29.7,33.4]

camaru@alumno.upv.es@ldsic-vdi07:~/W/SIN/PERCEPTRON$ python experiment.py videos '.1 1 10 100 1000 10000' '0.1'
#     a        b   E   k  Ete  Ete(%)     Ite [] 

#------- -------- --- --- --- ------- ----------

     0.1      0.1 1320 500 724  30.2   [28.4,32.1] 
     1.0      0.1 888 500 621  25.9   [24.2,27.7] 
    10.0      0.1 886 500 666  27.8   [26.0,29.6] 
   100.0      0.1 854 500 679  28.4   [26.5,30.2] 
  1000.0      0.1 864 500 682  28.5   [26.7,30.3] 
 10000.0      0.1 876 500 681  28.4   [26.6,30.2]

probando ahora el mismo aumento de k pero variando el margen, b, observamos que para k = 300, b= 1, a= 0.1 se disminuye el error estimado y los errores en el entrenamiento, mejorando los resultados. ->23.3   [21.6,25.0]
y con los mismos parámetros pero aumentando k a 500 aún conseguimos mejorarlos más. -> 22.0   [20.4,23.7]
Recordamos que para los mismos parámetros, con k=200 teníamos -> 27.0   [25.2,28.8] Ete% Ite%

A partir de b > 1 y para la misma k, los resultados empeoran

 camaru@alumno.upv.es@ldsic-vdi07:~/W/SIN/PERCEPTRON$ python experimentk.py videos '0.1' '.1 1 10 100 1000 10000 100000' '300'
#     a        b   E   k  Ete  Ete(%)     Ite [] 

#------- -------- --- --- --- ------- ----------

     0.1      0.1 1506 300 790  33.0   [31.1,34.9] 
     0.1      1.0 2630 300 558  23.3   [21.6,25.0] 
     0.1     10.0 4028 300 643  26.8   [25.1,28.6] 
     0.1    100.0 5564 300 753  31.4   [29.6,33.3] 
     0.1   1000.0 5564 300 1171  48.9   [46.9,50.9] 
     0.1  10000.0 5590 300 1171  48.9   [46.9,50.9] 
     0.1 100000.0 5590 300 1171  48.9   [46.9,50.9] 

camaru@alumno.upv.es@ldsic-vdi07:~/W/SIN/PERCEPTRON$ python experimentk.py videos '0.1' '.1 1 10 100 1000 10000 100000' '500'
#     a        b   E   k  Ete  Ete(%)     Ite [] 

#------- -------- --- --- --- ------- ----------

     0.1      0.1 1320 500 724  30.2   [28.4,32.1] 
     0.1      1.0 2410 500 528  22.0   [20.4,23.7] 
     0.1     10.0 3654 500 577  24.1   [22.4,25.8] 
     0.1    100.0 5530 500 882  36.8   [34.9,38.8] 
     0.1   1000.0 5565 500 1171  48.9   [46.9,50.9] 
     0.1  10000.0 5590 500 1171  48.9   [46.9,50.9] 
     0.1 100000.0 5590 500 1171  48.9   [46.9,50.9]

GAUSS2D dataset

values of a from 0.1 to 10,000

#     a        b   E   k  Ete  Ete(%)     Ite [] 

#------- -------- --- --- --- ------- ----------

     0.1      0.1 562 200 445  37.1   [34.4,39.8] 
     1.0      0.1 517 200 418  34.8   [32.1,37.5] 
    10.0      0.1 509 200 339  28.2   [25.7,30.8] 
   100.0      0.1 519 200 341  28.4   [25.9,31.0] 
  1000.0      0.1 529 200 485  40.4   [37.6,43.2] 
 10000.0      0.1 528 200 495  41.2   [38.5,44.0] 



 values of b from 0.1 to 100,000

#     a        b   E   k  Ete  Ete(%)     Ite [] 

#------- -------- --- --- --- ------- ----------

     0.1      0.1 562 200 445  37.1   [34.4,39.8] 
     0.1      1.0 697 200 260  21.7   [19.3,24.0] 
     0.1     10.0 806 200 141  11.8   [9.9,13.6] 
     0.1    100.0 824 200 126  10.5   [8.8,12.2] 
     0.1   1000.0 849 200 126  10.5   [8.8,12.2] 
     0.1  10000.0 1173 200 153  12.8   [10.9,14.6] 
     0.1 100000.0 1691 200 296  24.7   [22.2,27.1] 



GENDER dataset

values of a from 0.1 to 10,000

#     a        b   E   k  Ete  Ete(%)     Ite [] 

#------- -------- --- --- --- ------- ----------

     0.1      0.1   0  60  39   4.6   [3.2,6.0] 
     1.0      0.1   0  60  39   4.6   [3.2,6.0] 
    10.0      0.1   0  60  39   4.6   [3.2,6.0] 
   100.0      0.1   0  60  39   4.6   [3.2,6.0] 
  1000.0      0.1   0  60  39   4.6   [3.2,6.0] 
 10000.0      0.1   0  60  39   4.6   [3.2,6.0] 



 values of b from 0.1 to 100,000

#     a        b   E   k  Ete  Ete(%)     Ite [] 

#------- -------- --- --- --- ------- ----------

     0.1      0.1   0  60  39   4.6   [3.2,6.0] 
     0.1      1.0   0  60  39   4.6   [3.2,6.0] 
     0.1     10.0   0  70  49   5.8   [4.2,7.3] 
     0.1    100.0   0  70  49   5.8   [4.2,7.3] 
     0.1   1000.0   0  58  44   5.2   [3.7,6.7] 
     0.1  10000.0   0  66  43   5.1   [3.6,6.5] 
     0.1 100000.0   0  78  45   5.3   [3.8,6.8] 

los mejores valores para gender serían a=0.1 y b =1, para un menor error estimado 



